{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f8e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57916346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='David Goggins is an American ultramarathon runner, ultra-distance cyclist, triathlete, motivational speaker, and author. \\n\\nHe\\'s known for his incredible physical and mental toughness, pushing himself beyond what most consider humanly possible. \\n\\nHere are some of his prime achievements:\\n\\n* **Navy SEAL:** Goggins served as a Navy SEAL, completing Hell Week, the notoriously grueling training program, despite being severely undersized and facing intense physical and psychological challenges.\\n* **Ultra-Endurance Athlete:** He has broken numerous world records in ultra-endurance events, including:\\n    * Running 100 miles in under 15 hours\\n    * Completing 4,030 pull-ups in 48 hours\\n    * Running 143 miles in 24 hours while carrying a 40-pound backpack\\n* **Author:** Goggins is the author of the bestselling book \"Can\\'t Hurt Me,\" which details his incredible journey from childhood adversity to becoming a top athlete and motivational speaker.\\n* **Motivational Speaker:** He is a sought-after speaker, inspiring audiences with his message of overcoming adversity and pushing personal limits.\\n\\nGoggins\\' story is one of resilience, discipline, and self-belief. He encourages people to confront their fears, embrace discomfort, and achieve greatness through unwavering dedication and mental fortitude. \\n\\n\\nLet me know if you have any other questions about David Goggins.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 298, 'prompt_tokens': 26, 'total_tokens': 324, 'completion_time': 0.541818182, 'prompt_time': 0.00148574, 'queue_time': 0.249736929, 'total_time': 0.543303922}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f58b4550-1719-40f8-92fe-af02b30bc8ed-0', usage_metadata={'input_tokens': 26, 'output_tokens': 298, 'total_tokens': 324})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = ChatGroq(model =\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model.invoke(\"HI GROQ, tell me who is David Goggins and list his prime achievements?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c03cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a state\n",
    "class LLMState(TypedDict):\n",
    "    question : str\n",
    "    answer : str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e050a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_qa(state: LLMState) -> LLMState:\n",
    "    #extract the question from the state\n",
    "    question = state['question']\n",
    "\n",
    "    #form a prompt\n",
    "    prompt =f'Answer the Following question {question}'\n",
    "\n",
    "    # ask that question to the LLM\n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    # UPDATE THE answer in the state\n",
    "    state['answer'] = response\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd821531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create out graph\n",
    "graph = StateGraph(LLMState)\n",
    "\n",
    "#add nodes\n",
    "graph.add_node('llm_qa',llm_qa)\n",
    "\n",
    "#add edges\n",
    "graph.add_edge(START,'llm_qa')\n",
    "graph.add_edge('llm_qa',END)\n",
    "\n",
    "#compile\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8140b17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Explain Prompt Chaining in Langgraph in 50 Words',\n",
       " 'answer': \"Prompt chaining in LangChain allows you to break down complex tasks into smaller, sequential prompts. \\n\\nEach prompt's output becomes the input for the next, enabling the model to perform multi-step reasoning and generate more sophisticated responses. \\n\\n\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#execute\n",
    "initial_state ={'question':\"Explain Prompt Chaining in Langgraph in 50 Words\"}\n",
    "final_state= workflow.invoke(initial_state)\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9190d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPrompt Chaining: \\n\\nPrompt chaining in Langgraph leverages the outputs of previous prompts as input for subsequent ones, creating a chain of reasoning and enabling complex tasks.\\nIt's like a conversation where each response informs the next, guiding the language model towards a desired outcome.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Prompt Chaining: \n",
    "\n",
    "Prompt chaining in Langgraph leverages the outputs of previous prompts as input for subsequent ones, creating a chain of reasoning and enabling complex tasks.\n",
    "It's like a conversation where each response informs the next, guiding the language model towards a desired outcome.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "171d8bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Mahatma Gandhi was assassinated by **Nathuram Godse**, a Hindu nationalist, on **January 30, 1948**. \\n\\nGodse opposed Gandhi's philosophy of non-violence and his support for a separate Muslim-majority nation (Pakistan) during the partition of India. \\n\\nHe believed that Gandhi was too conciliatory towards Muslims and that his policies were weakening India.\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 22, 'total_tokens': 108, 'completion_time': 0.156363636, 'prompt_time': 0.001338058, 'queue_time': 0.254262061, 'total_time': 0.157701694}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--481ac414-be9d-4cbc-ab51-02fa0b8b4357-0', usage_metadata={'input_tokens': 22, 'output_tokens': 86, 'total_tokens': 108})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt =f'Answer the Following question why did mahatma gandhi die?'\n",
    "\n",
    "    # ask that question to the LLM\n",
    "response = model.invoke(prompt)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d8bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
